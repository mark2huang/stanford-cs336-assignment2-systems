{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.1 æ³¨æ„åŠ›æœºåˆ¶å®ç°çš„å¤šå°ºåº¦åŸºå‡†æµ‹è¯•**\n",
    "---\n",
    "\n",
    "è¯·ç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œåœ¨ä¸åŒçš„å°ºåº¦ä¸‹å¯¹ä½ å®ç°çš„æ³¨æ„åŠ›æœºåˆ¶è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚è„šæœ¬åº”åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "\n",
    "*   **(a)** å°†æ‰¹å¤§å°ï¼ˆBatch Sizeï¼‰å›ºå®šä¸º 8ï¼Œä¸”ä¸ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå³ï¼šç§»é™¤â€œå¤´â€ç»´åº¦ï¼Œå°†å…¶çœ‹ä½œå•å¤´ï¼‰ã€‚\n",
    "*   **(b)** éå†ä»¥ä¸‹å‚æ•°çš„ç¬›å¡å°”ç§¯ï¼šå¤´åµŒå…¥ç»´åº¦ $d_{model}$ å–å€¼ä¸º `[16, 32, 64, 128]`ï¼Œåºåˆ—é•¿åº¦ï¼ˆSequence Lengthï¼‰å–å€¼ä¸º `[256, 1024, 4096, 8192, 16384]`ã€‚\n",
    "*   **(c)** åˆ›å»ºå¯¹åº”å°ºå¯¸çš„éšæœºè¾“å…¥å¼ é‡ $Q, K, V$ã€‚\n",
    "*   **(d)** æµ‹é‡ä½¿ç”¨è¿™äº›è¾“å…¥è¿›è¡Œ 100 æ¬¡å‰å‘ä¼ æ’­ï¼ˆForward Passesï¼‰çš„æ—¶é—´ã€‚\n",
    "*   **(e)** åœ¨åå‘ä¼ æ’­å¼€å§‹å‰ï¼Œæµ‹é‡å½“å‰æ­£åœ¨ä½¿ç”¨çš„æ˜¾å­˜é‡ï¼ˆMemory in useï¼‰ï¼Œå¹¶æµ‹é‡ 100 æ¬¡åå‘ä¼ æ’­ï¼ˆBackward Passesï¼‰çš„æ—¶é—´ã€‚\n",
    "*   **(f)** ç¡®ä¿è¿›è¡Œé¢„çƒ­ï¼ˆWarm upï¼‰ï¼Œå¹¶ä¸”åœ¨æ¯æ¬¡å‰å‘/åå‘ä¼ æ’­ä¹‹åè°ƒç”¨ `torch.cuda.synchronize()`ï¼ˆä»¥ç¡®ä¿æµ‹é€Ÿå‡†ç¡®ï¼‰ã€‚\n",
    "\n",
    "**å®éªŒæŠ¥å‘Šè¦æ±‚ï¼š**\n",
    "\n",
    "æ±‡æŠ¥åœ¨è¿™äº›é…ç½®ä¸‹å¾—åˆ°çš„è€—æ—¶æ•°æ®ï¼ˆå¦‚æœæŠ¥é”™åˆ™æ±‡æŠ¥æ˜¾å­˜æº¢å‡ºé”™è¯¯ï¼Œå³ Out-of-Memory, OOMï¼‰ã€‚\n",
    "1.  åœ¨ä»€ä¹ˆæ ·çš„å°ºå¯¸ä¸‹ä¼šå‡ºç°æ˜¾å­˜æº¢å‡ºï¼ˆOOMï¼‰ï¼Ÿ\n",
    "2.  é’ˆå¯¹ä½ å‘ç°çš„å‡ºç° OOM çš„æœ€å°é…ç½®ä¹‹ä¸€ï¼Œè¿›è¡Œæ³¨æ„åŠ›æœºåˆ¶æ˜¾å­˜å ç”¨çš„â€œè´¦ç›®è®¡ç®—â€ï¼ˆä½ å¯ä»¥ä½¿ç”¨ Assignment 1 ä¸­å…³äº Transformer æ˜¾å­˜å ç”¨çš„è®¡ç®—å…¬å¼ï¼‰ã€‚\n",
    "3.  ä¸ºäº†åå‘ä¼ æ’­è€Œä¿å­˜ï¼ˆç¼“å­˜ï¼‰çš„æ˜¾å­˜é‡æ˜¯å¦‚ä½•éšåºåˆ—é•¿åº¦å˜åŒ–çš„ï¼Ÿ\n",
    "4.  ä½ ä¼šé‡‡å–ä»€ä¹ˆæ–¹æ³•æ¥æ¶ˆé™¤è¿™éƒ¨åˆ†æ˜¾å­˜å¼€é”€ï¼Ÿ\n",
    "\n",
    "**äº¤ä»˜ç‰©ï¼š**\n",
    "ä¸€ä»½åŒ…å«è€—æ—¶æ•°æ®çš„è¡¨æ ¼ã€æ˜¾å­˜å ç”¨çš„è®¡ç®—æ¨å¯¼è¿‡ç¨‹ï¼Œä»¥åŠ 1-2 æ®µæ–‡å­—çš„å›ç­”ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pytorch_naive_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    å®ç°æœ´ç´ çš„ PyTorch Attention: softmax(Q @ K.T / sqrt(dk)) @ V\n",
    "    \n",
    "    å‚æ•°:\n",
    "        q: Query å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)\n",
    "        k: Key å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)\n",
    "        v: Value å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)\n",
    "        mask: å¯é€‰çš„æ©ç å¼ é‡ (ä¾‹å¦‚ causal mask)\n",
    "        \n",
    "    è¿”å›:\n",
    "        output: æ³¨æ„åŠ›è®¡ç®—åçš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len, d_model)\n",
    "    \"\"\"\n",
    "    #step1:calculate attentionScore\n",
    "    attentionScore=q@k.transpose(-2,-1)\n",
    "\n",
    "    #step2:normalize\n",
    "    d_k=q.shape[-1]\n",
    "    attentionScore=attentionScore/d_k**0.5\n",
    "\n",
    "    #step3:mask\n",
    "    if mask is not None:\n",
    "        attentionScore=attentionScore.masked_fill(~mask,float('-inf'))\n",
    "\n",
    "    #step4:softmax\n",
    "    attentionScore=torch.softmax(attentionScore,dim=-1)\n",
    "\n",
    "    #step5:calculate output\n",
    "    output=attentionScore@v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_attention():\n",
    "    batch_size = 8\n",
    "    d_model_list = [16, 32, 64, 128]\n",
    "    seq_len_list = [256, 1024, 4096, 8192, 16384]\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    results = []\n",
    "\n",
    "    for d_model in d_model_list:\n",
    "        for seq_len in seq_len_list:\n",
    "            print(f\"Testing: d_model={d_model}, seq_len={seq_len}...\")\n",
    "            \n",
    "            # æ¸…ç†æ˜¾å­˜ç¼“å­˜\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            try:\n",
    "                # æ„é€ æ•°æ®ï¼Œéœ€è¦ requires_grad æ¥æµ‹è¯•åå‘ä¼ æ’­\n",
    "                q = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "                k = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "                v = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "\n",
    "                # --- 1. Warm up ---\n",
    "                for _ in range(10):\n",
    "                    _ = pytorch_naive_attention(q, k, v)\n",
    "\n",
    "                # --- 2. Measure Forward Pass ---\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                start_fwd = time.perf_counter()\n",
    "                \n",
    "                for _ in range(100):\n",
    "                    out = pytorch_naive_attention(q, k, v)\n",
    "                \n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                end_fwd = time.perf_counter()\n",
    "                avg_fwd = (end_fwd - start_fwd) / 100 * 1000  # è½¬ä¸º ms\n",
    "\n",
    "                # --- 3. Measure Memory ---\n",
    "                # åœ¨åå‘ä¼ æ’­å¼€å§‹å‰è®°å½•æ˜¾å­˜\n",
    "                mem_usage = torch.cuda.memory_allocated(device) / (1024 ** 2) # MB\n",
    "\n",
    "                # --- 4. Measure Backward Pass ---\n",
    "                grad_output = torch.randn_like(out)\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                start_bwd = time.perf_counter()\n",
    "                \n",
    "                for _ in range(100):\n",
    "                    out.backward(grad_output, retain_graph=True)\n",
    "                \n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                end_bwd = time.perf_counter()\n",
    "                avg_bwd = (end_bwd - start_bwd) / 100 * 1000 # ms\n",
    "\n",
    "                results.append({\n",
    "                    \"d_model\": d_model,\n",
    "                    \"seq_len\": seq_len,\n",
    "                    \"fwd_ms\": f\"{avg_fwd:.3f}\",\n",
    "                    \"bwd_ms\": f\"{avg_bwd:.3f}\",\n",
    "                    \"mem_mb\": f\"{mem_usage:.2f}\"\n",
    "                })\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(f\"OOM at seq_len={seq_len}\")\n",
    "                    results.append({\n",
    "                        \"d_model\": d_model,\n",
    "                        \"seq_len\": seq_len,\n",
    "                        \"fwd_ms\": \"OOM\",\n",
    "                        \"bwd_ms\": \"OOM\",\n",
    "                        \"mem_mb\": \"OOM\"\n",
    "                    })\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    # æ‰“å°ç»“æœè¡¨æ ¼ (ä½œä¸š 1.1.2 å»ºè®®ä½¿ç”¨ pandas æ‰“å°è¡¨æ ¼)\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nBenchmark Results:\")\n",
    "    print(df.to_markdown()) # éœ€è¦ pip install tabulate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Benchmark Results:\n",
    "|    |   d_model |   seq_len | fwd_ms   | bwd_ms   | mem_mb   |\n",
    "|---:|----------:|----------:|:---------|:---------|:---------|\n",
    "|  0 |        16 |       256 | 0.118    | 6.040    | 10.62    |\n",
    "|  1 |        16 |      1024 | 1.241    | 2.177    | 50.38    |\n",
    "|  2 |        16 |      4096 | 15.336   | 29.282   | 536.75   |\n",
    "|  3 |        16 |      8192 | 64.601   | 120.728  | 2082.25  |\n",
    "|  4 |        16 |     16384 | OOM      | OOM      | OOM      |\n",
    "|  5 |        32 |       256 | 0.102    | 0.431    | 23.25    |\n",
    "|  6 |        32 |      1024 | 1.241    | 2.184    | 52.50    |\n",
    "|  7 |        32 |      4096 | 16.176   | 30.388   | 545.25   |\n",
    "|  8 |        32 |      8192 | 67.603   | 128.251  | 2100.25  |\n",
    "|  9 |        32 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 10 |        64 |       256 | 0.108    | 0.307    | 28.25    |\n",
    "| 11 |        64 |      1024 | 1.306    | 2.512    | 56.75    |\n",
    "| 12 |        64 |      4096 | 19.095   | 34.864   | 562.25   |\n",
    "| 13 |        64 |      8192 | 81.289   | 152.397  | 2136.25  |\n",
    "| 14 |        64 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 15 |       128 |       256 | 0.201    | 0.423    | 38.25    |\n",
    "| 16 |       128 |      1024 | 1.807    | 3.657    | 65.25    |\n",
    "| 17 |       128 |      4096 | 27.715   | 52.034   | 596.25   |\n",
    "| 18 |       128 |      8192 | 127.961  | 238.462  | 2208.25  |\n",
    "| 19 |       128 |     16384 | OOM      | OOM      | OOM      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å®éªŒæŠ¥å‘Šè¦æ±‚ï¼š\n",
    "\n",
    "æ±‡æŠ¥åœ¨è¿™äº›é…ç½®ä¸‹å¾—åˆ°çš„è€—æ—¶æ•°æ®ï¼ˆå¦‚æœæŠ¥é”™åˆ™æ±‡æŠ¥æ˜¾å­˜æº¢å‡ºé”™è¯¯ï¼Œå³ Out-of-Memory, OOMï¼‰ã€‚\n",
    "\n",
    "## Q1ï¼šåœ¨ä»€ä¹ˆæ ·çš„å°ºå¯¸ä¸‹ä¼šå‡ºç°æ˜¾å­˜æº¢å‡ºï¼ˆOOMï¼‰ï¼Ÿ\n",
    "é’ˆå¯¹ä½ å‘ç°çš„å‡ºç° OOM çš„æœ€å°é…ç½®ä¹‹ä¸€ï¼Œè¿›è¡Œæ³¨æ„åŠ›æœºåˆ¶æ˜¾å­˜å ç”¨çš„â€œè´¦ç›®è®¡ç®—â€ï¼ˆä½ å¯ä»¥ä½¿ç”¨ Assignment 1 ä¸­å…³äº Transformer æ˜¾å­˜å ç”¨çš„è®¡ç®—å…¬å¼ï¼‰ã€‚\n",
    "A:å½“seq_len=16384çš„æ—¶å€™ï¼Œä¸ç®¡d_modelå¤§å°ï¼Œå†…å­˜éƒ½ä¼šæº¢å‡º\n",
    "\n",
    "Q,K,V Matrix=batchSize*d_model*seq_len*3*4byte=8*16*16384*3*4=0.02GB\n",
    "\n",
    "Forward:attentionScore=batchsize*seq_len*seq_len*4byte=8*16384*16384*4=8GB\n",
    "\n",
    "Backward:ä¿ç•™å‰å‘çš„çŸ©é˜µ8GB\n",
    "\n",
    "total=QKVMatrix+Forward+Backward>16GBï¼ˆGPU T4*2ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.0\n",
    "\n",
    "---\n",
    "\n",
    "### **é—®é¢˜ (torch_compile)ï¼š2åˆ†**\n",
    "\n",
    "**(a)** æ‰©å±•ä½ ä¹‹å‰çš„æ³¨æ„åŠ›æœºåˆ¶åŸºå‡†æµ‹è¯•è„šæœ¬ï¼ŒåŠ å…¥ä½ æ‰€å®ç°çš„ PyTorch æ³¨æ„åŠ›æœºåˆ¶çš„**ç¼–è¯‘ç‰ˆæœ¬ï¼ˆcompiled versionï¼‰**ã€‚åœ¨ä¸ä¸Šè¿° `pytorch_attention` é—®é¢˜ï¼ˆå³ 1.2.1 èŠ‚ï¼‰ç›¸åŒçš„é…ç½®ä¸‹ï¼Œå¯¹æ¯”å…¶ä¸éç¼–è¯‘ç‰ˆæœ¬çš„æ€§èƒ½ã€‚\n",
    "\n",
    "*   **äº¤ä»˜ç‰©**ï¼šä¸€å¼ å¯¹æ¯”è¡¨æ ¼ï¼Œæ¯”è¾ƒç¼–è¯‘åçš„æ³¨æ„åŠ›æ¨¡å—ä¸ä¹‹å‰ `pytorch_attention` é—®é¢˜ä¸­éç¼–è¯‘ç‰ˆæœ¬çš„**å‰å‘ï¼ˆforwardï¼‰**å’Œ**åå‘ï¼ˆbackwardï¼‰**ä¼ æ’­è€—æ—¶ã€‚\n",
    "\n",
    "**(b)** ç°åœ¨ï¼Œåœ¨ä½ ä¹‹å‰çš„ç«¯åˆ°ç«¯åŸºå‡†æµ‹è¯•è„šæœ¬ï¼ˆå³ 1.1.3 èŠ‚ä¸­ç”¨äºæµ‹è¯•æ•´ä¸ªæ¨¡å‹çš„è„šæœ¬ï¼‰ä¸­ï¼Œ**ç¼–è¯‘ä½ çš„æ•´ä¸ª Transformer æ¨¡å‹**ã€‚å‰å‘ä¼ æ’­çš„æ€§èƒ½å‘ç”Ÿäº†æ€æ ·çš„å˜åŒ–ï¼Ÿå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ä»¥åŠä¼˜åŒ–å™¨æ­¥éª¤ï¼ˆoptimizer stepsï¼‰ç»„åˆåœ¨ä¸€èµ·çš„æ•´ä½“æ€§èƒ½åˆå‘ç”Ÿäº†æ€æ ·çš„å˜åŒ–ï¼Ÿ\n",
    "\n",
    "*   **äº¤ä»˜ç‰©**ï¼šä¸€å¼ å¯¹æ¯”è¡¨æ ¼ï¼Œæ¯”è¾ƒ**åŸå§‹åŸç”Ÿï¼ˆvanillaï¼‰** Transformer æ¨¡å‹ä¸**ç¼–è¯‘åï¼ˆcompiledï¼‰** Transformer æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **ğŸ’¡ ä»»åŠ¡é‡ç‚¹è¯´æ˜ï¼š**\n",
    "\n",
    "#### **1. é’ˆå¯¹ (a) çš„å®ç°ï¼š**\n",
    "ä½ ä¸éœ€è¦å†™æ–°å‡½æ•°ï¼Œåªéœ€è¦åˆ©ç”¨ `torch.compile`ã€‚\n",
    "*   **åšæ³•**ï¼šåœ¨æµ‹è¯•å¾ªç¯å¼€å§‹å‰ï¼Œæ‰§è¡Œ `compiled_fn = torch.compile(pytorch_naive_attention)`ã€‚\n",
    "*   **æ„ä¹‰**ï¼šä½ ä¼šè§‚å¯Ÿåˆ°ï¼Œç”±äº `torch.compile` å°è¯•å°†çŸ©é˜µä¹˜æ³•ã€é™¤æ³•ã€Maskã€Softmax è¿™äº›æ“ä½œâ€œèåˆâ€è¿›æ›´å°‘çš„ GPU å†…æ ¸ï¼ˆKernelsï¼‰ä¸­ï¼Œå‡å°‘äº†æ˜¾å­˜è¯»å†™æ¬¡æ•°ï¼Œé€Ÿåº¦åº”è¯¥ä¼šæœ‰æå‡ã€‚\n",
    "\n",
    "#### **2. é’ˆå¯¹ (b) çš„å®ç°ï¼š**\n",
    "è¿™æ¬¡æ˜¯é’ˆå¯¹**æ•´ä¸ªæ¨¡å‹ç±»**ã€‚\n",
    "*   **åšæ³•**ï¼š`compiled_model = torch.compile(model)`ã€‚\n",
    "*   **æµ‹é‡å†…å®¹**ï¼šè¿™æ¬¡ä¸ä»…ä»…æµ‹ Attention å‡½æ•°ï¼Œè¿˜è¦æµ‹é‡ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ­¥ï¼ˆTraining Stepï¼‰ï¼ŒåŒ…æ‹¬ï¼š\n",
    "    1.  `output = compiled_model(input)`ï¼ˆå‰å‘ï¼‰\n",
    "    2.  `loss.backward()`ï¼ˆåå‘ï¼‰\n",
    "    3.  `optimizer.step()`ï¼ˆä¼˜åŒ–å™¨æ›´æ–°ï¼‰\n",
    "*   **æ„ä¹‰**ï¼šå…¨æ¨¡å‹ç¼–è¯‘é€šå¸¸æ¯”å•å‡½æ•°ç¼–è¯‘æœ‰æ›´å¤§çš„ä¼˜åŒ–ç©ºé—´ï¼Œå› ä¸ºå®ƒèƒ½è·¨å±‚è¿›è¡Œç®—å­èåˆã€‚\n",
    "\n",
    "#### **3. âš ï¸ å®éªŒé™·é˜±æé†’ï¼š**\n",
    "*   **é¢„çƒ­ï¼ˆWarm-upï¼‰**ï¼š`torch.compile` åœ¨**ç¬¬ä¸€æ¬¡æ‰§è¡Œ**æ—¶ä¼šéå¸¸æ…¢ï¼Œå› ä¸ºå®ƒåœ¨åå°è°ƒç”¨ Triton ç”Ÿæˆå†…æ ¸ä»£ç ã€‚ä½ å¿…é¡»åœ¨è®¡æ—¶å¾ªç¯å¼€å§‹å‰ï¼Œå…ˆè·‘å‡ æ¬¡æ¨¡å‹ï¼Œç¡®ä¿ç¼–è¯‘å®Œæˆã€‚\n",
    "*   **æ˜¾å­˜**ï¼šæ³¨æ„è§‚å¯Ÿï¼Œè™½ç„¶é€Ÿåº¦å˜å¿«äº†ï¼Œä½†åœ¨é•¿åºåˆ—ï¼ˆå¦‚ 16384ï¼‰ä¸‹ï¼Œç¼–è¯‘ç‰ˆæ˜¯å¦ä¾ç„¶ä¼šæŠ¥é”™ OOMï¼Ÿï¼ˆç­”æ¡ˆé€šå¸¸æ˜¯ï¼šæ˜¯çš„ï¼Œå› ä¸ºå®ƒä¾ç„¶è¦å­˜ $N^2$ çš„æ³¨æ„åŠ›çŸ©é˜µï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_attention():\n",
    "    batch_size = 8\n",
    "    d_model_list = [16, 32, 64, 128]\n",
    "    seq_len_list = [256, 1024, 4096, 8192, 16384]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "        print(f\"GPU Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"Total Memory: {props.total_memory / 1024**2:.2f} MB\")\n",
    "        print(f\"Processor Count: {props.multi_processor_count}\")\n",
    "        print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "    else:\n",
    "        device =\"cpu\"\n",
    "    results = []\n",
    "\n",
    "    compiled_naive_attention = torch.compile(pytorch_naive_attention)\n",
    "    for d_model in d_model_list:\n",
    "        for seq_len in seq_len_list:\n",
    "            print(f\"Testing: d_model={d_model}, seq_len={seq_len}...\")\n",
    "            \n",
    "            # æ¸…ç†æ˜¾å­˜ç¼“å­˜\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            try:\n",
    "                # æ„é€ æ•°æ®ï¼Œéœ€è¦ requires_grad æ¥æµ‹è¯•åå‘ä¼ æ’­\n",
    "                q = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "                k = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "                v = torch.randn(batch_size, seq_len, d_model, device=device, requires_grad=True)\n",
    "\n",
    "                # --- 1. Warm up ---\n",
    "                for _ in range(10):\n",
    "                    warm_up_out = compiled_naive_attention(q, k, v)\n",
    "                    warm_up_out.backward(torch.randn_like(warm_up_out))\n",
    "                    \n",
    "                # --- 2. Measure Forward Pass ---\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                start_fwd = time.perf_counter()\n",
    "                \n",
    "                for _ in range(100):\n",
    "                    out = compiled_naive_attention(q, k, v)\n",
    "                \n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                end_fwd = time.perf_counter()\n",
    "                avg_fwd = (end_fwd - start_fwd) / 100 * 1000  # è½¬ä¸º ms\n",
    "\n",
    "                # --- 3. Measure Memory ---\n",
    "                # åœ¨åå‘ä¼ æ’­å¼€å§‹å‰è®°å½•æ˜¾å­˜\n",
    "                mem_usage = torch.cuda.memory_allocated(device) / (1024 ** 2) # MB\n",
    "\n",
    "                # --- 4. Measure Backward Pass ---\n",
    "                grad_output = torch.randn_like(out)\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                start = time.perf_counter()\n",
    "                \n",
    "                for _ in range(100):\n",
    "                    out=compiled_naive_attention(q,k,v)\n",
    "                    out.backward(grad_output)\n",
    "                if device == \"cuda\": torch.cuda.synchronize()\n",
    "                end = time.perf_counter()\n",
    "                avg_fwd_bwd = (end - start) / 100 * 1000 # ms æ³¨æ„è¿™é‡ŒåŒ…å«å‰å‘å’Œåå‘çš„æ—¶é—´\n",
    "                real_bwd_ms=avg_fwd_bwd-avg_fwd\n",
    "\n",
    "                results.append({\n",
    "                    \"d_model\": d_model,\n",
    "                    \"seq_len\": seq_len,\n",
    "                    \"fwd_ms\": f\"{avg_fwd:.3f}\",\n",
    "                    \"bwd_ms\": f\"{real_bwd_ms:.3f}\",\n",
    "                    \"mem_mb\": f\"{mem_usage:.2f}\"\n",
    "                })\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(f\"OOM at seq_len={seq_len}\")\n",
    "                    results.append({\n",
    "                        \"d_model\": d_model,\n",
    "                        \"seq_len\": seq_len,\n",
    "                        \"fwd_ms\": \"OOM\",\n",
    "                        \"bwd_ms\": \"OOM\",\n",
    "                        \"mem_mb\": \"OOM\"\n",
    "                    })\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    # æ‰“å°ç»“æœè¡¨æ ¼ (ä½œä¸š 1.3.1 å»ºè®®ä½¿ç”¨ pandas æ‰“å°è¡¨æ ¼)\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\nBenchmark Results:\")\n",
    "    print(df.to_markdown()) # éœ€è¦ pip install tabulate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T09:27:39.648818Z",
     "iopub.status.busy": "2026-02-18T09:27:39.648436Z",
     "iopub.status.idle": "2026-02-18T09:27:39.657034Z",
     "shell.execute_reply": "2026-02-18T09:27:39.656004Z",
     "shell.execute_reply.started": "2026-02-18T09:27:39.648790Z"
    }
   },
   "source": [
    "- Is CUDA available: True\n",
    "- GPU Device Name: Tesla T4\n",
    "- Total Memory: 14912.69 MB\n",
    "- Processor Count: 40\n",
    "- Compute Capability: 7.5\n",
    "\n",
    "before complie:\n",
    "|    |   d_model |   seq_len | fwd_ms   | bwd_ms   | mem_mb   |\n",
    "|---:|----------:|----------:|:---------|:---------|:---------|\n",
    "|  0 |        16 |       256 | 0.118    | 6.040    | 10.62    |\n",
    "|  1 |        16 |      1024 | 1.241    | 2.177    | 50.38    |\n",
    "|  2 |        16 |      4096 | 15.336   | 29.282   | 536.75   |\n",
    "|  3 |        16 |      8192 | 64.601   | 120.728  | 2082.25  |\n",
    "|  4 |        16 |     16384 | OOM      | OOM      | OOM      |\n",
    "|  5 |        32 |       256 | 0.102    | 0.431    | 23.25    |\n",
    "|  6 |        32 |      1024 | 1.241    | 2.184    | 52.50    |\n",
    "|  7 |        32 |      4096 | 16.176   | 30.388   | 545.25   |\n",
    "|  8 |        32 |      8192 | 67.603   | 128.251  | 2100.25  |\n",
    "|  9 |        32 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 10 |        64 |       256 | 0.108    | 0.307    | 28.25    |\n",
    "| 11 |        64 |      1024 | 1.306    | 2.512    | 56.75    |\n",
    "| 12 |        64 |      4096 | 19.095   | 34.864   | 562.25   |\n",
    "| 13 |        64 |      8192 | 81.289   | 152.397  | 2136.25  |\n",
    "| 14 |        64 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 15 |       128 |       256 | 0.201    | 0.423    | 38.25    |\n",
    "| 16 |       128 |      1024 | 1.807    | 3.657    | 65.25    |\n",
    "| 17 |       128 |      4096 | 27.715   | 52.034   | 596.25   |\n",
    "| 18 |       128 |      8192 | 127.961  | 238.462  | 2208.25  |\n",
    "| 19 |       128 |     16384 | OOM      | OOM      | OOM      |\n",
    "\n",
    "\n",
    "after compile:\n",
    "|    |   d_model |   seq_len | fwd_ms   | bwd_ms   | mem_mb   |\n",
    "|---:|----------:|----------:|:---------|:---------|:---------|\n",
    "|  0 |        16 |       256 | 0.354    | 0.487    | 19.25    |\n",
    "|  1 |        16 |      1024 | 1.315    | 1.227    | 52.38    |\n",
    "|  2 |        16 |      4096 | 15.356   | 23.546   | 544.75   |\n",
    "|  3 |        16 |      8192 | 65.147   | 98.962   | 2098.25  |\n",
    "|  4 |        16 |     16384 | OOM      | OOM      | OOM      |\n",
    "|  5 |        32 |       256 | 0.939    | 0.860    | 24.25    |\n",
    "|  6 |        32 |      1024 | 3.713    | 4.169    | 56.50    |\n",
    "|  7 |        32 |      4096 | 23.691   | 32.629   | 561.25   |\n",
    "|  8 |        32 |      8192 | 80.472   | 124.365  | 2132.25  |\n",
    "|  9 |        32 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 10 |        64 |       256 | 0.969    | 0.878    | 30.25    |\n",
    "| 11 |        64 |      1024 | 3.990    | 4.636    | 64.75    |\n",
    "| 12 |        64 |      4096 | 28.613   | 41.088   | 594.25   |\n",
    "| 13 |        64 |      8192 | 102.531  | 168.196  | 2200.25  |\n",
    "| 14 |        64 |     16384 | OOM      | OOM      | OOM      |\n",
    "| 15 |       128 |       256 | 1.091    | 0.925    | 42.25    |\n",
    "| 16 |       128 |      1024 | 4.598    | 5.939    | 81.25    |\n",
    "| 17 |       128 |      4096 | 40.429   | 60.686   | 660.25   |\n",
    "| 18 |       128 |      8192 | 147.319  | 250.266  | 2336.25  |\n",
    "| 19 |       128 |     16384 | OOM      | OOM      | OOM      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Example - Weighted Sum (Triton å…¥é—¨)\n",
    "---\n",
    "**å®ƒæ˜¯åšä»€ä¹ˆçš„ï¼š**\n",
    "å¦‚ä½•ç”¨ Triton ç¼–å†™ä¸€ä¸ªç®€å•çš„å†…æ ¸ï¼šè®¡ç®—çŸ©é˜µ $X$ æ¯ä¸€è¡Œä¸å‘é‡ $w$ çš„ç‚¹ç§¯ã€‚\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¦å…ˆçœ‹è¿™ä¸ªï¼š**\n",
    "*   **ç†è§£â€œåˆ†å—æŒ‡é’ˆâ€ (Block Pointers)**ï¼šè¿™æ˜¯ Triton çš„æ ¸å¿ƒã€‚ä»¥å‰å†™ CUDA ç®—ç´¢å¼•å¾ˆç—›è‹¦ï¼ˆè¦ç®— `threadIdx`, `blockIdx` ç­‰ï¼‰ï¼ŒTriton ä½¿ç”¨ `tl.make_block_ptr` è®©ä½ åƒæ“ä½œåˆ‡ç‰‡ä¸€æ ·æ“ä½œ GPU å†…å­˜ã€‚\n",
    "*   **ç†è§£â€œæ­¥è¿›â€ (Advance)**ï¼šå­¦ä¹ å¦‚ä½•ç”¨ `ptr.advance` åœ¨å†…å­˜ä¸­ç§»åŠ¨ä½ çš„çª—å£ã€‚\n",
    "*   **ä»£ç å°è£…**ï¼šå­¦ä¹ å¦‚ä½•æŠŠ Triton å†…æ ¸åŒ…è£…è¿› `torch.autograd.Function` çš„ `forward` å’Œ `backward` ä¸­ï¼Œä½¿å…¶èƒ½æ— ç¼èå…¥ PyTorch çš„è®­ç»ƒæµç¨‹ã€‚\n",
    "\n",
    "**ä½ åº”è¯¥æ€ä¹ˆåšï¼š**\n",
    "1.  **ä¸è¦è·³è¿‡é˜…è¯»**ï¼šä»”ç»†é˜…è¯» PDF ç¬¬ 10-14 é¡µçš„ä»£ç ã€‚\n",
    "2.  **åœ¨ Kaggle æ‰‹æ•²ä¸€é**ï¼šå°è¯•è¿è¡Œ PDF ä¸­æä¾›çš„ `weighted_sum` ä»£ç ã€‚\n",
    "3.  **ç†è§£åå‘ä¼ æ’­**ï¼šçœ‹æ‡‚æ¢¯åº¦ $dw$ å’Œ $dx$ æ˜¯å¦‚ä½•åœ¨ Triton å¾ªç¯é‡Œç´¯åŠ çš„ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:39:40.058793Z",
     "iopub.status.busy": "2026-02-22T09:39:40.058186Z",
     "iopub.status.idle": "2026-02-22T09:39:40.188230Z",
     "shell.execute_reply": "2026-02-22T09:39:40.187708Z",
     "shell.execute_reply.started": "2026-02-22T09:39:40.058761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#1.3.1 Example - Weighted Sum\n",
    "def weighted_sum(x,weight):\n",
    "    # æ­¤å¤„å‡è®¾ x çš„ç»´åº¦æ˜¯ [..., D]ï¼Œweight çš„ç»´åº¦æ˜¯ [D],ç»´åº¦ä¸åŒ¹é…ï¼Œ å¹¿æ’­+ç‚¹ç§¯\n",
    "    return (weight *x).sum(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "import torch\n",
    "#å‰å‘ä¼ æ’­\n",
    "@triton.jit\n",
    "def weight_sum_fwd(\n",
    "    x_ptr,weight_ptr, #è¾“å…¥æŒ‡é’ˆ\n",
    "    output_ptr, #è¾“å‡ºæŒ‡é’ˆ\n",
    "    x_row_stride,x_stride_dim,#æ­¥é•¿ï¼Œå‘Šè¯‰æˆ‘ä»¬å¦‚ä½•åœ¨å¼ é‡çš„æ¯ä¸ªè½´ä¸Šç§»åŠ¨ä¸€ä¸ªå…ƒç´ \n",
    "    weight_stride_dim,#é€šå¸¸ä¸º1\n",
    "    output_stride_row,#é€šå¸¸ä¸º1\n",
    "    ROWS,D,#çŸ©é˜µæ€»è¡Œæ•°å’Œç»´åº¦\n",
    "    ROWS_TILE_SIZE:tl.constexpr,\n",
    "    D_TILE_SIZE: tl.constexpr,#åˆ†å—å¤§å°ï¼šå¿…é¡»åœ¨ç¼–è¯‘æ—¶å·²çŸ¥ å¯¹äº3*2çš„çŸ©é˜µROWS_TILE_SIZE=1ï¼ŒD_TILE_SIZE=2\n",
    "):\n",
    "    #æ¯ä¸ªå®ä¾‹å°†è®¡ç®—ä¸€ç»„è¡Œåˆ†å—çš„åŠ æƒå’Œ\n",
    "    # tl.program_id(0) æŒ‡ç¤ºå½“å‰åœ¨å“ªä¸ªçº¿ç¨‹å—\n",
    "    row_tile_idx=tl.program_id(0)\n",
    "    \n",
    "    #å—æŒ‡é’ˆï¼ˆBlock pointersï¼‰ è®©æˆ‘ä»¬èƒ½é€‰æ‹©å†…å­˜ä¸­çš„ä¸€ä¸ªNç»´åŒºåŸŸå¹¶ç§»åŠ¨å®ƒ\n",
    "    \"\"\"\n",
    "    å—æŒ‡é’ˆéœ€è¦çŸ¥é“ï¼š\n",
    "    - æŒ‡å‘å¼ é‡çš„ç¬¬ä¸€ä¸ªå…ƒç´ çš„æŒ‡é’ˆ\n",
    "    - å¼ é‡çš„æ€»å½¢çŠ¶ï¼ˆä»¥å¤„ç†è¶Šç•Œè®¿é—®ï¼‰\n",
    "    - æ¯ä¸ªç»´åº¦çš„æ­¥é•¿ï¼ˆä»¥æ­£ç¡®ä½¿ç”¨å†…å­˜å¸ƒå±€ï¼‰\n",
    "    - èµ·å§‹å—çš„Nç»´åæ ‡(offsets)\n",
    "    - æ¯æ¬¡åŠ è½½/å­˜å‚¨æ—¶ä½¿ç”¨çš„å—å½¢çŠ¶\n",
    "    - ç»´åº¦åœ¨å†…å­˜ä¸­çš„æ’åˆ—é¡ºåº\n",
    "    \"\"\"\n",
    "    x_block_ptr=tl.make_block_ptr(\n",
    "        x_ptr,\n",
    "        shape=(ROWS,D,),\n",
    "        strides=(x_row_stride,x_stride_dim),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE,0),\n",
    "        block_shape=(ROWS_TILE_SIZE,D_TILE_SIZE),\n",
    "        order=(1,0),\n",
    "    )\n",
    "\n",
    "    weight_block_ptr=tl.make_block_ptr(\n",
    "        weight_ptr,\n",
    "        shape=(D,),\n",
    "        strides=(weight_stride_dim,),\n",
    "        offsets=(0,),\n",
    "        block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "\n",
    "    output_block_ptr=tl.make_block_ptr(\n",
    "        output_ptr,\n",
    "        shape=(ROWS,),\n",
    "        strides=(output_stride_row,),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE,),\n",
    "        block_shape=(ROWS_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "    #åˆå§‹åŒ–ä¸€ä¸ªç¼“å†²åŒºç”¨äºå†™å…¥ç»“æœ\n",
    "    output=tl.zeros((ROWS_TILE_SIZE,),dtype=tl.float32)\n",
    "    #åœ¨Dç»´åº¦ä¸Šè¿›è¡Œå¾ªç¯\n",
    "    for i in range(tl.cdiv(D,D_TILE_SIZE)):\n",
    "        #åŠ è½½å½“å‰çš„å—æŒ‡é’ˆå†…å®¹å¹¶å¸¦æœ‰è¾¹ç•Œæ£€æŸ¥\n",
    "        row=tl.load(x_block_ptr,boundary_check=(0,1),padding_option=\"zero\")\n",
    "        weight=tl.load(weight_block_ptr,boundary_check=(0,),padding_option=\"zero\")\n",
    "\n",
    "        #è®¡ç®—è¯¥è¡Œåˆ†å—çš„åŠ æƒå’Œ\n",
    "        output+=tl.sum(row*weight[None,:],axis=1)\n",
    "\n",
    "        #å°†æŒ‡é’ˆç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªåˆ†å—\n",
    "        x_block_ptr=x_block_ptr.advance((0,D_TILE_SIZE))\n",
    "        weight_block_ptr=weight_block_ptr.advance((D_TILE_SIZE,))\n",
    "    #å°†ç»“æœå†™å›è¾“å‡ºå¿«æŒ‡é’ˆ\n",
    "    tl.store(output_block_ptr,output,boundary_check=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:39:43.229791Z",
     "iopub.status.busy": "2026-02-22T09:39:43.229066Z",
     "iopub.status.idle": "2026-02-22T09:39:43.241284Z",
     "shell.execute_reply": "2026-02-22T09:39:43.240718Z",
     "shell.execute_reply.started": "2026-02-22T09:39:43.229749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#åå‘ä¼ æ’­\n",
    "@triton.jit\n",
    "def weighted_sum_backward(\n",
    "    x_ptr,weight_ptr, #input\n",
    "    grad_output_ptr, # Grad input\n",
    "    grad_x_ptr,partial_grad_weight_ptr,#Grad outputs\n",
    "    stride_xr,stride_xd,\n",
    "    stride_wd,\n",
    "    stride_gr,\n",
    "    stride_gxr,stride_gxd,\n",
    "    stride_gwb,stride_gwd,\n",
    "    NUM_ROWS,D,#3,2\n",
    "    ROWS_TILE_SIZE:tl.constexpr,D_TILE_SIZE:tl.constexpr,#Tile Size å¿…é¡»æ˜¯ 2 çš„å¹‚ï¼ŒROWS_TILE_SIZE=1ï¼ŒD_TILE_SIZE=2\n",
    "):\n",
    "    row_tile_idx=tl.program_id(0)\n",
    "    n_row_tiles=tl.num_programs(0)\n",
    "\n",
    "    #è®¡ç®—Xçš„æ¢¯åº¦wjâ‹…gi\n",
    "    #è®¡ç®—weightçš„æ¢¯åº¦sum(xij*gi)\n",
    "    #Inputs X=3*2\n",
    "    #weight=2*1\n",
    "    #weight_sum/ouput/gradout=3*1\n",
    "    \"\"\"\n",
    "    åœºæ™¯:å‡è®¾3*2çŸ©é˜µè®¡ç®—å®Œå.å¾—åˆ°äº†ä¸€ä¸ªé•¿åº¦ä¸º 3 çš„è¾“å‡ºå‘é‡y\n",
    "    è¾“å…¥æ¢¯åº¦ï¼šç°åœ¨åå‘ä¼ æ’­ä¼ å›äº†ä¸€ä¸ªé•¿åº¦ä¸º 3 çš„æ¢¯åº¦å‘é‡ grad_output = [g0, g1, g2]\n",
    "    \"\"\"\n",
    "    grad_output_block_ptr=tl.make_block_ptr(\n",
    "        base=grad_output_ptr,#åœ°å›¾çš„èµ·ç‚¹ï¼šæ•´ä¸ªå‘é‡åœ¨æ˜¾å­˜é‡Œçš„â€œé—¨ç‰Œå·â€èµ·ç‚¹\n",
    "        shape=(NUM_ROWS,),#åœ°å›¾çš„å…¨é•¿ï¼šå‘Šè¯‰ GPU è¿™æ¡æ•°æ®æ€»å…±æœ‰å¤šé•¿ï¼Œåˆ«è·‘ä¸¢äº†\n",
    "        strides=(stride_gr,),#æ­¥é•¿ï¼šä»ä¸€ä¸ªæ¢¯åº¦å€¼èµ°åˆ°ä¸‹ä¸€ä¸ªæ¢¯åº¦å€¼ï¼Œéœ€è¦è·¨è¿‡å¤šå°‘ä¸ªåœ°å€ç©ºé—´\n",
    "        offsets=(row_tile_idx*ROWS_TILE_SIZE,),#å½“å‰å·¥äººçš„èµ·å§‹ç‚¹ï¼šå·¥äººiåº”è¯¥ä»ç¬¬å‡ ä¸ªæ¢¯åº¦å¼€å§‹çœ‹\n",
    "        block_shape=(ROWS_TILE_SIZE,),#æ‰‹ç”µç­’çš„å®½åº¦ï¼šå·¥äººä¸€æ¬¡æ€§èƒ½çœ‹å‡ ä¸ªæ¢¯åº¦å€¼ï¼Ÿ\n",
    "        order=(0,),#æ‰«ææ–¹å‘ï¼šæ•°æ®æ˜¯æŒ‰ä»€ä¹ˆé¡ºåºæ’çš„ï¼Ÿï¼ˆ1D åªæœ‰ä¸€ç§æ’æ³•ï¼‰\n",
    "    )\n",
    "    x_block_ptr=tl.make_block_ptr(\n",
    "        base=x_ptr,\n",
    "        shape=(NUM_ROWS,D,),\n",
    "        strides=(stride_xr,stride_xd),\n",
    "        offsets=(row_tile_idx*ROWS_TILE_SIZE,0),\n",
    "        block_shape=(ROWS_TILE_SIZE,D_TILE_SIZE),\n",
    "        order=(1,0),\n",
    "    )\n",
    "    weight_block_ptr=tl.make_block_ptr(\n",
    "        base=weight_ptr,\n",
    "        shape=(D,),#å¦‚æœä½ çš„ shape åªæœ‰ä¸€ä¸ªæ•°ï¼ˆä¸€ç»´ï¼‰ï¼Œé‚£ä¹ˆä½ çš„ offsets å’Œ block_shape ä¹Ÿåªèƒ½æœ‰ä¸€ä¸ªæ•°\n",
    "        strides=(stride_wd,),\n",
    "        offsets=(0,),\n",
    "        block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "    )\n",
    "    grad_x_block_ptr=tl.make_block_ptr(\n",
    "        base=grad_x_ptr,\n",
    "        shape=(NUM_ROWS,D,),\n",
    "        strides=(stride_gxr,stride_gxd),\n",
    "        offsets=(row_tile_idx*ROWS_TILE_SIZE,0),\n",
    "        block_shape=(ROWS_TILE_SIZE,D_TILE_SIZE),\n",
    "        order=(1,0),\n",
    "    )\n",
    "    partial_grad_weight_block_ptr=tl.make_block_ptr( #æ ¹æ®å…¬å¼ (3)ï¼Œæƒé‡ wçš„æ¢¯åº¦æ˜¯æ‰€æœ‰è¡Œç´¯åŠ çš„ç»“æœã€‚ç”±äºæ¯ä¸ªå·¥äººå¤„ç†ä¸åŒçš„è¡Œï¼Œä»–ä»¬æ¯ä¸ªäººéƒ½ä¼šç®—å‡ºä¸€ä¸ªå¯¹wçš„â€œå±€éƒ¨è´¡çŒ®â€,æ‰€ä»¥è®©æ¯ä¸ªå·¥äººæŠŠè‡ªå·±çš„è®¡ç®—ç»“æœå†™åˆ°ä¸€ä¸ªå« partial_grad_weight_ptr çš„ç¼“å†²åŒºé‡Œ\n",
    "        base=partial_grad_weight_ptr,\n",
    "        shape=(NUM_ROWS,D,),\n",
    "        strides=(stride_gwb,stride_gwd),\n",
    "        offsets=(row_tile_idx,0),\n",
    "        block_shape=(1,D_TILE_SIZE),\n",
    "        order=(1,0),\n",
    "\n",
    "    )\n",
    "    for i in range(tl.cdiv(D,D_TILE_SIZE)):\n",
    "        # 1. åŠ è½½è¾“å‡ºæ¢¯åº¦ï¼šå·¥äºº 1 åŠ è½½ g1ã€‚å½¢çŠ¶ä¸º (1,)\n",
    "        grad_output=tl.load(grad_output_block_ptr,boundary_check=(0,),padding_option=\"zero\") #(ROWS_TILE_SIZE,)\n",
    "        # 2. åŠ è½½æƒé‡ï¼šåŠ è½½ [w0, w1]ã€‚å½¢çŠ¶ä¸º (2,)\n",
    "        weight=tl.load(weight_block_ptr,boundary_check=(0,),padding_option=\"zero\")#(D_TILE_SIZE,)\n",
    "        \n",
    "        #3.è®¡ç®—Xçš„æ¢¯åº¦wjâ‹…gi åœ¨ Tritonå’Œ PyTorchä¸­ï¼ŒNone çš„ä½œç”¨æ˜¯å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥ä¾¿è§¦å‘å¹¿æ’­æœºåˆ¶\n",
    "        grad_x_row=grad_output[:,None]*weight[None,:]\n",
    "        # 4. å­˜å‚¨ X çš„æ¢¯åº¦ï¼šæŠŠ [[g1*w0, g1*w1]] å†™å›åˆ° grad_x çŸ©é˜µçš„ç¬¬ 2 è¡Œ\n",
    "        tl.store(grad_x_block_ptr,grad_x_row,boundary_check=(0,1))\n",
    "\n",
    "        # 5. è®¡ç®— weight çš„éƒ¨åˆ†æ¢¯åº¦ (å…¬å¼ 3): (nabla_w)_j = sum(x_ij * g_i)\n",
    "        row=tl.load(x_block_ptr,boundary_check=(0,1),padding_option=\"zero\")#(ROWS_TILE_SIZE,D_TILE_SIZE)\n",
    "        grad_weight_row=tl.sum(row*grad_output[:,None],axis=0,keep_dims=True)\n",
    "        tl.store(partial_grad_weight_block_ptr,grad_weight_row,boundary_check=(1,))# Never out of bounds for dim 0\n",
    "        \n",
    "        # Move the pointers to the next tile along D\n",
    "        x_block_ptr=x_block_ptr.advance((0,D_TILE_SIZE))\n",
    "        weight_block_ptr=weight_block_ptr.advance((D_TILE_SIZE,))\n",
    "        partial_grad_weight_block_ptr=partial_grad_weight_block_ptr.advance((0,D_TILE_SIZE))\n",
    "        grad_x_block_ptr=grad_x_block_ptr.advance((0,D_TILE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†å½»åº•çœ‹æ¸…è¿™è¡Œä»£ç åœ¨ GPU å¯„å­˜å™¨é‡Œæ˜¯å¦‚ä½•è¿ç®—çš„ï¼Œæˆ‘ä»¬å¸¦å…¥å…·ä½“æ•°å€¼ã€‚\n",
    "\n",
    "### 1. åœºæ™¯è®¾å®š\n",
    "*   **è¾“å…¥æƒé‡ $weight$**: `[7, 8]`\n",
    "*   **å‡è®¾è¾“å‡ºæ¢¯åº¦ $grad\\_output$**: `[1, 2, 3]` ï¼ˆæˆ‘ä»¬å‡è®¾è¿™ä¸‰ä¸ªæ•°æ˜¯åå‘ä¼ æ’­ä¼ å›æ¥çš„ï¼‰\n",
    "*   **å½“å‰å·¥äºº**: å·¥äºº 1ï¼ˆ`row_tile_idx = 1`ï¼‰ï¼Œä»–è´Ÿè´£å¤„ç† $X$ çš„**ç¬¬ 2 è¡Œ**ï¼ˆå³æ•°å€¼ä¸º `[3, 4]` çš„é‚£ä¸€è¡Œï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2. é€æ­¥è®¡ç®—è¿‡ç¨‹\n",
    "\n",
    "#### ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ•°æ®ï¼ˆLoadï¼‰\n",
    "å·¥äºº 1 ä»æ˜¾å­˜ä¸­é€šè¿‡ `tl.load` æ‹¿åˆ°å±äºè‡ªå·±çš„é‚£éƒ¨åˆ†æ•°æ®ï¼š\n",
    "*   **`grad_output`**: æ‹¿åˆ°ç¬¬ 1 ä¸ªå…ƒç´ ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰ï¼Œæ•°å€¼ä¸º **`2`**ã€‚\n",
    "*   **`weight`**: æ‹¿åˆ°å®Œæ•´çš„æƒé‡ï¼Œæ•°å€¼ä¸º **`[7, 8]`**ã€‚\n",
    "\n",
    "#### ç¬¬äºŒæ­¥ï¼šç»´åº¦é‡å¡‘ï¼ˆUnsqueeze/Noneï¼‰\n",
    "åœ¨ Tritonï¼ˆå’Œ PyTorchï¼‰ä¸­ï¼Œ`None` çš„ä½œç”¨æ˜¯å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥ä¾¿è§¦å‘**å¹¿æ’­æœºåˆ¶**ã€‚\n",
    "\n",
    "1.  **`grad_output[:, None]`**:\n",
    "    *   åŸå½¢çŠ¶ï¼š`[1]`ï¼ˆæ ‡é‡/1Då‘é‡ï¼‰\n",
    "    *   æ–°å½¢çŠ¶ï¼š`(1, 1)`ï¼ˆåˆ—å‘é‡ï¼‰\n",
    "    *   **æ•°å€¼ï¼š`[[2]]`**\n",
    "\n",
    "2.  **`weight[None, :]`**:\n",
    "    *   åŸå½¢çŠ¶ï¼š`[2]`ï¼ˆ1Då‘é‡ï¼‰\n",
    "    *   æ–°å½¢çŠ¶ï¼š`(1, 2)`ï¼ˆè¡Œå‘é‡ï¼‰\n",
    "    *   **æ•°å€¼ï¼š`[[7, 8]]`**\n",
    "\n",
    "#### ç¬¬ä¸‰æ­¥ï¼šé€å…ƒç´ ç›¸ä¹˜ï¼ˆOuter Product / å¤–ç§¯ï¼‰\n",
    "ä»£ç ï¼š`grad_x_row = grad_output[:, None] * weight[None, :]`\n",
    "\n",
    "è¿™å°±æ˜¯ä¸€ä¸ª **(1, 1)** çš„çŸ©é˜µ ä¹˜ä»¥ä¸€ä¸ª **(1, 2)** çš„çŸ©é˜µï¼š\n",
    "$$ \\begin{bmatrix} 2 \\end{bmatrix} \\times \\begin{bmatrix} 7 & 8 \\end{bmatrix} $$\n",
    "\n",
    "æ ¹æ®å¹¿æ’­è§„åˆ™ï¼Œ`[[2]]` ä¼šè¢«è‡ªåŠ¨å¤åˆ¶æˆ `[[2, 2]]` æ¥åŒ¹é…å®½åº¦ï¼Œç„¶åè¿›è¡Œå¯¹åº”ç›¸ä¹˜ï¼š\n",
    "*   ç¬¬ä¸€ä¸ªä½ç½®ï¼š$2 \\times 7 = 14$\n",
    "*   ç¬¬äºŒä¸ªä½ç½®ï¼š$2 \\times 8 = 16$\n",
    "\n",
    "**è®¡ç®—ç»“æœ `grad_x_row`**: **`[[14, 16]]`**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ç»“æœçš„ç‰©ç†å«ä¹‰\n",
    "\n",
    "è¿™ä¸ªç»“æœ `[[14, 16]]` å°±æ˜¯æŸå¤±å‡½æ•°å¯¹ $X$ çŸ©é˜µä¸­**ç¬¬ 2 è¡Œ**ä¸¤ä¸ªå…ƒç´ çš„æ¢¯åº¦ï¼š\n",
    "\n",
    "*   å¯¹äºå…ƒç´  `3` ($x_{10}$)ï¼šå®ƒçš„æ¢¯åº¦æ˜¯ **14**ã€‚\n",
    "*   å¯¹äºå…ƒç´  `4` ($x_{11}$)ï¼šå®ƒçš„æ¢¯åº¦æ˜¯ **16**ã€‚\n",
    "\n",
    "**å·¥äºº 1 æœ€åçš„åŠ¨ä½œ**ï¼š\n",
    "ä»–è°ƒç”¨ `tl.store(grad_x_block_ptr, grad_x_row)`ï¼ŒæŠŠè¿™ç»„æ•° `[14, 16]` å­˜å›åˆ°æ˜¾å­˜ä¸­ `grad_x` çŸ©é˜µçš„ç¬¬äºŒè¡Œä½ç½®ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 4. ä¸ºä»€ä¹ˆè¿™å«â€œå¤–ç§¯â€ï¼Ÿ\n",
    "\n",
    "å¦‚æœä½ æŠŠä¸‰ä¸ªå·¥äººçš„è®¡ç®—ç»“æœåˆåœ¨ä¸€èµ·çœ‹ï¼Œä½ ä¼šå‘ç°æ•´ä¸ª `grad_x` çŸ©é˜µå…¶å®å°±æ˜¯ä¸¤ä¸ªå‘é‡çš„ä¹˜ç§¯ï¼š\n",
    "\n",
    "$$ \\nabla_x L = \\begin{bmatrix} g_0 \\\\ g_1 \\\\ g_2 \\end{bmatrix} \\times \\begin{bmatrix} w_0 & w_1 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 7 & 1 \\cdot 8 \\\\ 2 \\cdot 7 & 2 \\cdot 8 \\\\ 3 \\cdot 7 & 3 \\cdot 8 \\end{bmatrix} = \\begin{bmatrix} 7 & 8 \\\\ 14 & 16 \\\\ 21 & 24 \\end{bmatrix} $$\n",
    "\n",
    "*   **å‰å‘ä¼ æ’­**ï¼šæ˜¯æ¯ä¸€è¡Œå’Œ $w$ åš**å†…ç§¯**ï¼ˆç‚¹ç§¯ï¼‰ï¼Œå˜æˆä¸€ä¸ªæ•°ã€‚\n",
    "*   **åå‘ä¼ æ’­**ï¼šæ˜¯è¾“å‡ºæ¢¯åº¦å’Œ $w$ åš**å¤–ç§¯**ï¼Œé‡æ–°å˜å›ä¸€ä¸ªçŸ©é˜µã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç»§ç»­æ²¿ç”¨ $3 \\times 2$ æ¡ˆä¾‹ï¼Œçœ‹çœ‹**å·¥äºº 1**ï¼ˆè´Ÿè´£ç¬¬ 2 è¡Œï¼‰æ˜¯å¦‚ä½•è®¡ç®—æƒé‡ $w$ çš„æ¢¯åº¦çš„ã€‚\n",
    "\n",
    "### 1. åœºæ™¯è®¾å®š\n",
    "*   **è¾“å…¥çŸ©é˜µ $X$ çš„ç¬¬ 2 è¡Œ (`row`)**: `[3, 4]`\n",
    "*   **è¾“å‡ºæ¢¯åº¦ $grad\\_output$ ($g$) çš„ç¬¬ 2 ä¸ªå€¼**: `2`\n",
    "*   **æƒé‡ $w$ çš„é•¿åº¦**: 2ï¼ˆå¯¹åº” $w_0, w_1$ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### 2. é€æ­¥è®¡ç®—è¿‡ç¨‹\n",
    "\n",
    "#### ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ•°æ®ï¼ˆLoadï¼‰\n",
    "å·¥äºº 1 é€šè¿‡æŒ‡é’ˆæ‹¿åˆ°ä»–éœ€è¦çš„â€œåŸææ–™â€ï¼š\n",
    "*   **`row`**: æ‹¿åˆ° $X$ çš„ç¬¬ 1 è¡Œï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰ï¼Œæ•°å€¼ä¸º **`[3, 4]`**ã€‚\n",
    "*   **`grad_output`**: æ‹¿åˆ°è¾“å‡ºæ¢¯åº¦çš„ç¬¬ 1 ä¸ªå€¼ï¼Œæ•°å€¼ä¸º **`2`**ã€‚\n",
    "\n",
    "#### ç¬¬äºŒæ­¥ï¼šå‡†å¤‡ä¹˜æ³•ç»´åº¦ï¼ˆBroadcastingï¼‰\n",
    "ä»£ç ï¼š`row * grad_output[:, None]`\n",
    "\n",
    "1.  **`row`**: å½¢çŠ¶æ˜¯ `(1, 2)`ï¼Œæ•°å€¼æ˜¯ `[[3, 4]]`ã€‚\n",
    "2.  **`grad_output[:, None]`**: å½¢çŠ¶æ˜¯ `(1, 1)`ï¼Œæ•°å€¼æ˜¯ `[[2]]`ã€‚\n",
    "\n",
    "è¿›è¡Œé€å…ƒç´ ç›¸ä¹˜æ—¶ï¼Œ`[[2]]` ä¼šå¹¿æ’­ï¼ˆå¤åˆ¶ï¼‰æˆ `[[2, 2]]`ï¼š\n",
    "*   ç¬¬ä¸€ä¸ªä½ç½®ï¼š$3 \\times 2 = 6$\n",
    "*   ç¬¬äºŒä¸ªä½ç½®ï¼š$4 \\times 2 = 8$\n",
    "\n",
    "**å¾—åˆ°ä¸­é—´ç»“æœ**ï¼š**`[[6, 8]]`**ã€‚\n",
    "è¿™ä¸ªç»“æœçš„ç‰©ç†å«ä¹‰æ˜¯ï¼š**â€œä»…æ ¹æ®ç¬¬ 2 è¡Œçš„æ•°æ®ï¼Œæˆ‘è®¤ä¸º $w_0$ åº”è¯¥æ›´æ–° 6ï¼Œ $w_1$ åº”è¯¥æ›´æ–° 8â€**ã€‚\n",
    "\n",
    "#### ç¬¬ä¸‰æ­¥ï¼šå±€éƒ¨æ±‚å’Œï¼ˆReductionï¼‰\n",
    "ä»£ç ï¼š`grad_weight_row = tl.sum(..., axis=0, keep_dims=True)`\n",
    "\n",
    "*   å› ä¸ºæˆ‘ä»¬çš„ `ROWS_TILE_SIZE = 1`ï¼ˆæ¯ä¸ªå·¥äººåªç®¡ä¸€è¡Œï¼‰ï¼Œæ‰€ä»¥è¿™ä¸€æ­¥åœ¨ `axis=0`ï¼ˆè¡Œæ–¹å‘ï¼‰ä¸Šæ±‚å’Œï¼Œå…¶å®å°±æ˜¯å®ƒè‡ªå·±ã€‚\n",
    "*   **ç»“æœ `grad_weight_row`**: **`[[6, 8]]`**ã€‚\n",
    "\n",
    "> **æ³¨ï¼š** å¦‚æœ `ROWS_TILE_SIZE = 16`ï¼Œè¿™ä¸ªå·¥äººä¼šä¸€æ¬¡æ€§è¯»å…¥ 16 è¡Œï¼Œé‚£ä¹ˆè¿™æ­¥ `tl.sum` å°±ä¼šæŠŠè¿™ 16 è¡Œå¯¹ $w$ çš„è´¡çŒ®å…¨éƒ¨åŠ èµ·æ¥ï¼Œç¼©å‡æˆä¸€è¡Œ `[dw0, dw1]`ã€‚\n",
    "\n",
    "#### ç¬¬å››æ­¥ï¼šå­˜å‚¨åˆ°å±€éƒ¨ç¼“å†²åŒºï¼ˆPartial Storeï¼‰\n",
    "ä»£ç ï¼š`tl.store(partial_grad_weight_block_ptr, grad_weight_row)`\n",
    "\n",
    "å·¥äºº 1 å°†ä»–çš„ç»“æœ `[6, 8]` å†™åˆ° `partial_grad_weight` è¿™ä¸ªå¤§çŸ©é˜µçš„**ç¬¬ 1 è¡Œ**ï¼ˆå¯¹åº”ä»–çš„å·¥å·ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 3. å…¨å±€è§†è§’ï¼šä¸‰ä¸ªå·¥äººå¹²å®Œæ´»åçš„æ ·å­\n",
    "\n",
    "å½“æ‰€æœ‰å·¥äººï¼ˆ0, 1, 2ï¼‰éƒ½å®Œæˆä¸Šè¿°æ­¥éª¤åï¼Œ`partial_grad_weight` çŸ©é˜µåœ¨æ˜¾å­˜é‡Œé•¿è¿™æ ·ï¼š\n",
    "\n",
    "| å·¥äººç¼–å· | è®¡ç®—è¿‡ç¨‹ | å±€éƒ¨æ¢¯åº¦ç»“æœ (å†™åœ¨çŸ©é˜µå¯¹åº”çš„è¡Œ) |\n",
    "| :--- | :--- | :--- |\n",
    "| **å·¥äºº 0** | $g_0 \\times [x_{00}, x_{01}] = 1 \\times [1, 2]$ | **`[1, 2]`** |\n",
    "| **å·¥äºº 1** | $g_1 \\times [x_{10}, x_{11}] = 2 \\times [3, 4]$ | **`[6, 8]`** |\n",
    "| **å·¥äºº 2** | $g_2 \\times [x_{20}, x_{21}] = 3 \\times [5, 6]$ | **`[15, 18]`** |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. æœ€ç»ˆæ±‡æ€»ï¼ˆåœ¨å†…æ ¸ä¹‹å¤–ï¼‰\n",
    "\n",
    "ç°åœ¨ï¼Œæ˜¾å­˜é‡Œæœ‰ä¸€ä¸ª $3 \\times 2$ çš„ `partial_grad_weight` çŸ©é˜µã€‚ä½† PyTorch æœ€ç»ˆéœ€è¦çš„ $\\nabla_w L$ åªæ˜¯ä¸€ä¸ªé•¿åº¦ä¸º 2 çš„å‘é‡ã€‚\n",
    "\n",
    "äºæ˜¯ï¼Œåœ¨ Python åŒ…è£…ç±»çš„ `backward` å‡½æ•°ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„ä¸€è¡Œï¼š\n",
    "```python\n",
    "# æŠŠæ‰€æœ‰å·¥äººçš„å±€éƒ¨è´¡çŒ®åŠ èµ·æ¥ï¼Œå¾—åˆ°æœ€ç»ˆçš„æƒé‡æ¢¯åº¦\n",
    "grad_weight = partial_grad_weight.sum(axis=0)\n",
    "```\n",
    "**è®¡ç®—æœ€ç»ˆç»“æœï¼š**\n",
    "*   $w_0$ çš„æ€»æ¢¯åº¦ $= 1 + 6 + 15 = \\mathbf{22}$\n",
    "*   $w_1$ çš„æ€»æ¢¯åº¦ $= 2 + 8 + 18 = \\mathbf{28}$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ ä¸ºä»€ä¹ˆä¸ç›´æ¥åœ¨ Triton é‡ŒåŠ åˆ°ä¸€ä¸ªå‘é‡ä¸Šï¼Ÿ\n",
    "\n",
    "ä½ å¯èƒ½ä¼šé—®ï¼šä¸ºä»€ä¹ˆå·¥äººä»¬ä¸ç›´æ¥å¾€åŒä¸€ä¸ª `grad_weight` å‘é‡é‡ŒåŠ ï¼Ÿ\n",
    "\n",
    "1.  **ç«äº‰ï¼ˆRace Conditionï¼‰**ï¼šå¦‚æœå·¥äºº 0 å’Œå·¥äºº 1 åŒæ—¶è®¡ç®—å®Œï¼Œéƒ½è¦å†™åŒä¸€ä¸ªå†…å­˜åœ°å€ï¼Œä¼šå‘ç”Ÿå†²çªï¼Œå¯¼è‡´ç»“æœé”™è¯¯ã€‚\n",
    "2.  **åŸå­æ“ä½œå¤ªæ…¢**ï¼šè™½ç„¶å¯ä»¥ä½¿ç”¨ `tl.atomic_add` æ¥å¼ºè¡Œå†™å…¥ï¼Œä½†åŸå­æ“ä½œä¼šè®© GPU çº¿ç¨‹æ’é˜Ÿï¼Œå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚\n",
    "3.  **åˆ†æ²»æ³•ï¼ˆMap-Reduceï¼‰**ï¼šè®©æ¯ä¸ªå·¥äººå†™è‡ªå·±çš„ä½ç½®ï¼ˆMapï¼‰ï¼Œæœ€åç»Ÿä¸€æ±‚å’Œï¼ˆReduceï¼‰ï¼Œè¿™æ˜¯é«˜æ€§èƒ½è®¡ç®—ä¸­æœ€æ ‡å‡†ã€æœ€é«˜æ•ˆçš„å¥—è·¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:43:40.971915Z",
     "iopub.status.busy": "2026-02-22T09:43:40.971248Z",
     "iopub.status.idle": "2026-02-22T09:43:40.982007Z",
     "shell.execute_reply": "2026-02-22T09:43:40.981338Z",
     "shell.execute_reply.started": "2026-02-22T09:43:40.971881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from einops import rearrange\n",
    "\n",
    "def cdiv(a, b):\n",
    "    return (a + b - 1) // b\n",
    "\n",
    "class WeightedSumFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight):\n",
    "        # 1. é¢„å¤„ç†\n",
    "        ctx.original_x_shape = x.shape  # ä¿å­˜çŸ©é˜µåŸå§‹å½¢çŠ¶\n",
    "        input_shape = x.shape\n",
    "        D = input_shape[-1]\n",
    "        x_flattened = rearrange(x, \"... d -> (...) d\").contiguous()\n",
    "        weight = weight.contiguous()\n",
    "        \n",
    "        n_rows = x_flattened.shape[0]\n",
    "        y = torch.empty((n_rows,), device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        # 2. å—å¤§å°è®¾ç½®\n",
    "        # æ³¨æ„ï¼šD_TILE_SIZE å¿…é¡»æ˜¯ 2 çš„å¹‚ä¸”ä¸èƒ½è¶…è¿‡ D\n",
    "        D_TILE_SIZE = min(128, triton.next_power_of_2(D)) \n",
    "        ROWS_TILE_SIZE = 16\n",
    "        \n",
    "        # 3. è°ƒç”¨å†…æ ¸\n",
    "        grid = (cdiv(n_rows, ROWS_TILE_SIZE), )\n",
    "        weight_sum_fwd[grid](\n",
    "            x_ptr=x_flattened, \n",
    "            weight_ptr=weight, \n",
    "            output_ptr=y,\n",
    "            x_row_stride=x_flattened.stride(0), \n",
    "            x_stride_dim=x_flattened.stride(1),\n",
    "            weight_stride_dim=weight.stride(0),\n",
    "            output_stride_row=1, # ã€ä¿®æ­£ç‚¹ 1ã€‘ä¸€ç»´å‘é‡è¾“å‡ºæ­¥é•¿å›ºå®šä¸º 1\n",
    "            ROWS=n_rows, D=D,\n",
    "            ROWS_TILE_SIZE=ROWS_TILE_SIZE,\n",
    "            D_TILE_SIZE=D_TILE_SIZE,\n",
    "        )\n",
    "        \n",
    "        ctx.save_for_backward(x_flattened, weight)\n",
    "        ctx.ROWS_TILE_SIZE = ROWS_TILE_SIZE\n",
    "        ctx.D_TILE_SIZE = D_TILE_SIZE\n",
    "        \n",
    "        return y.view(input_shape[:-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        x, weight = ctx.saved_tensors\n",
    "        n_rows, D = x.shape\n",
    "        ROWS_TILE_SIZE = ctx.ROWS_TILE_SIZE\n",
    "        D_TILE_SIZE = ctx.D_TILE_SIZE\n",
    "        \n",
    "        # å±•å¹³ grad_out ä»¥åŒ¹é… 1D é€»è¾‘\n",
    "        grad_out = grad_out.reshape(-1).contiguous()\n",
    "        \n",
    "        grad_x = torch.empty_like(x)\n",
    "        n_row_tiles = cdiv(n_rows, ROWS_TILE_SIZE)\n",
    "        partial_grad_weight = torch.zeros((n_row_tiles, D), device=x.device, dtype=x.dtype)\n",
    "\n",
    "        grid = (n_row_tiles, )\n",
    "        weighted_sum_backward[grid](\n",
    "            x_ptr=x, weight_ptr=weight,\n",
    "            grad_output_ptr=grad_out,\n",
    "            grad_x_ptr=grad_x, \n",
    "            partial_grad_weight_ptr=partial_grad_weight,\n",
    "            stride_xr=x.stride(0), stride_xd=x.stride(1),\n",
    "            stride_wd=weight.stride(0),\n",
    "            stride_gr=grad_out.stride(0),\n",
    "            stride_gxr=grad_x.stride(0), stride_gxd=grad_x.stride(1),\n",
    "            stride_gwb=partial_grad_weight.stride(0), stride_gwd=partial_grad_weight.stride(1),\n",
    "            NUM_ROWS=n_rows, D=D,\n",
    "            ROWS_TILE_SIZE=ROWS_TILE_SIZE, D_TILE_SIZE=D_TILE_SIZE,\n",
    "        )\n",
    "        \n",
    "        grad_weight = partial_grad_weight.sum(axis=0)\n",
    "        return grad_x.view(ctx.original_x_shape), grad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:45:43.213706Z",
     "iopub.status.busy": "2026-02-22T09:45:43.212931Z",
     "iopub.status.idle": "2026-02-22T09:45:43.226881Z",
     "shell.execute_reply": "2026-02-22T09:45:43.226223Z",
     "shell.execute_reply.started": "2026-02-22T09:45:43.213675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor: tensor([[  8.5580,  -5.5923,  10.1044,  ...,  -2.9318,  16.2322,  -9.8391],\n",
      "        [ 31.9812,   6.1009,   2.6397,  ..., -12.8501,  10.3944,  -3.1172],\n",
      "        [-11.6288,  18.4553, -32.0443,  ...,   6.1585,   0.8947,   5.9122],\n",
      "        ...,\n",
      "        [  4.3335,  -6.8354,  -3.6885,  ..., -23.5979, -18.3236, -15.0220],\n",
      "        [ 12.0635,   4.7010, -21.5463,  ...,  -2.5938,  -5.2389,   8.9815],\n",
      "        [-18.2658,   9.1820,   5.1162,  ...,   9.7913, -16.5786,   0.5825]],\n",
      "       device='cuda:0', grad_fn=<WeightedSumFuncBackward>)\n",
      "Attached grad_fn: <torch.autograd.function.WeightedSumFuncBackward object at 0x79e3e8977790>\n",
      "Forward Correctness: True\n",
      "X gradient calculated: True\n",
      "Weight gradient calculated: True\n",
      "Backward Correctness: True\n"
     ]
    }
   ],
   "source": [
    "import os; \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# 1. å®ä¾‹åŒ–\n",
    "f_weightedsum = WeightedSumFunc.apply\n",
    "\n",
    "# 2. å‡†å¤‡æ•°æ® (requires_grad=True æ‰èƒ½æµ‹åå‘)\n",
    "batch, seq, d = 8, 512, 128\n",
    "x = torch.randn(batch, seq, d, device='cuda', requires_grad=True)\n",
    "w = torch.randn(d, device='cuda', requires_grad=True)\n",
    "\n",
    "# 3. è¿è¡ŒTriton ç®—å­ (Forward)\n",
    "output_triton = f_weightedsum(x, w)\n",
    "\n",
    "# --- éªŒè¯ç‚¹ 1: æ£€æŸ¥ grad_fn ---\n",
    "print(f\"Output Tensor: {output_triton}\")\n",
    "print(f\"Attached grad_fn: {output_triton.grad_fn}\") \n",
    "# è¿™é‡Œä½ åº”è¯¥èƒ½çœ‹åˆ° <WeightedSumFuncBackward>ï¼Œè¿™è¯æ˜ PyTorch å·²ç»â€œè®°ä½â€äº†ä½ çš„ç®—å­\n",
    "\n",
    "# --- éªŒè¯ç‚¹ 2: æ£€æŸ¥ç»“æœæ­£ç¡®æ€§ (ä¸åŸç”Ÿ PyTorch å¯¹æ¯”) ---\n",
    "output_pytorch = (w * x).sum(dim=-1)\n",
    "# å…è®¸å¾®å°çš„æµ®ç‚¹è¯¯å·®\n",
    "is_correct = torch.allclose(output_triton, output_pytorch, atol=1e-5)\n",
    "print(f\"Forward Correctness: {is_correct}\")\n",
    "\n",
    "# --- éªŒè¯ç‚¹ 3: æ£€æŸ¥åå‘ä¼ æ’­ (Backward) ---\n",
    "# å‡è®¾å¯¹ output çš„æ€»å’Œæ±‚å¯¼\n",
    "loss = output_triton.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"X gradient calculated: {x.grad is not None}\")\n",
    "print(f\"Weight gradient calculated: {w.grad is not None}\")\n",
    "\n",
    "# å¯¹æ¯” X çš„æ¢¯åº¦\n",
    "x_grad_triton = x.grad.clone()\n",
    "x.grad.zero_()\n",
    "(w * x).sum().backward()\n",
    "print(f\"Backward Correctness: {torch.allclose(x_grad_triton, x.grad, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
